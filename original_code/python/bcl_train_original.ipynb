{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "iteration: 0\n",
      "Znew = \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.44912526]]\n",
      "\n",
      "##################################################\n",
      "iteration: 1\n",
      "Znew = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.80231439 0.37624982 0.28828397 0.2144073  0.15818236]]\n",
      "\n",
      "##################################################\n",
      "iteration: 2\n",
      "Znew = \n",
      "[[1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.90322068 0.12756125 0.56830803 0.31131225 0.27412053]]\n",
      "\n",
      "##################################################\n",
      "iteration: 3\n",
      "Znew = \n",
      "[[1. 0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.95091632 0.40780335 0.5163652  0.61098064 0.49323681 0.22157953]]\n",
      "\n",
      "##################################################\n",
      "iteration: 4\n",
      "Znew = \n",
      "[[1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.80825685 0.58364202 0.28155488 0.24363964 0.49679553]]\n",
      "\n",
      "##################################################\n",
      "iteration: 5\n",
      "Znew = \n",
      "[[1. 1. 0. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.94612175 0.5656945  0.15935169 0.1820401 ]]\n",
      "\n",
      "##################################################\n",
      "iteration: 6\n",
      "Znew = \n",
      "[[1. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.92197033 0.29483553 0.21904701 0.18758713]]\n",
      "\n",
      "##################################################\n",
      "iteration: 7\n",
      "Znew = \n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.94379018 0.42263551 0.3305956  0.50458055 0.2817836  0.32925209\n",
      "  0.44084483]]\n",
      "\n",
      "##################################################\n",
      "iteration: 8\n",
      "Znew = \n",
      "[[1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.983661   0.11821195 0.26963478 0.48355661 0.66838266 0.51776787\n",
      "  0.54114605]]\n",
      "\n",
      "##################################################\n",
      "iteration: 9\n",
      "Znew = \n",
      "[[1. 1. 0. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Rnew = \n",
      "[[0.72578602 0.51980739 0.18257818 0.21248275 0.27257248 0.42261852\n",
      "  0.39034616]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy.stats import beta, multivariate_normal, poisson\n",
    "from scipy.linalg import inv\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# for matlab code to run in vscode pip install https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html\n",
    "data = scipy.io.loadmat(\"/home/ari/Desktop/Bayesian/BCL/chunk_learner_python/input_2001_Exp1.mat\")\n",
    "\n",
    "X = data[\"X\"]\n",
    "V = data[\"V\"]\n",
    "X_test = data[\"Xtest\"]\n",
    "V_test = data[\"Vtest\"]\n",
    "\n",
    "N, T = X.shape\n",
    "\n",
    "#params\n",
    "lda = 0.999\n",
    "eps = 0.01\n",
    "sigmaU = 3\n",
    "sigmaV = 3\n",
    "sigmaC = 0.1\n",
    "phi = 4\n",
    "bAlpha = 1.0\n",
    "bBeta = 1.0\n",
    "alpha = 0.1\n",
    "trainingLength = 6\n",
    "Kmax = 1\n",
    "wburn = 5\n",
    "wsample = 10\n",
    "stepNo = 10\n",
    "burnIn = 0\n",
    "\n",
    "def calc_pv_trial(x, v, y, Z, sigmaU, sigmaV, phi):\n",
    "    N, K = Z.shape\n",
    "    ZAct = Z * np.tile(y.flatten(), (N, 1))\n",
    "\n",
    "    phi = phi * ZAct\n",
    "    zc = np.logical_and(phi, x)\n",
    "\n",
    "    xAct = np.where(x == 1)[0] + 1\n",
    "    xActNo = len(xAct)\n",
    "    A = phi / (1 + np.tile(np.sum(phi, axis=1, keepdims=True), (1,K)))\n",
    "\n",
    "    sSq = (sigmaV ** 2 / (1 + np.sum(phi, axis=1)))\n",
    "    ptAct  = np.where(np.sum(ZAct * (np.tile(x.flatten(), (K,1)).T), axis=0))[0] + 1 # to match matlab indexing\n",
    "    ptNo = len(ptAct)\n",
    "\n",
    "    SigmaInv = np.zeros((ptNo, ptNo, len(xAct)))\n",
    "    omegaBU = np.zeros((N, N))\n",
    "    diag_values = np.diag(sSq[xAct-1])\n",
    "    omega = 1 / sigmaV**4 * diag_values\n",
    "\n",
    "    availLinks = []\n",
    "    availLinksRow = []\n",
    "    availLinksCol = []\n",
    "\n",
    "    if np.sum(Z) != 0:\n",
    "        availLinksRow, availLinksCol = np.where(Z) # col, row = 1, 0 in matlab 2, 1\n",
    "        availLinks = np.column_stack((availLinksRow+1, availLinksCol+1)) # to match matlab indexing of Z\n",
    "        availLinkNo = availLinks.shape[0]\n",
    "        SigmaCtllhInv = np.zeros((availLinkNo, availLinkNo))\n",
    "        wt = np.zeros((availLinkNo, 2))\n",
    "    else:\n",
    "        availLinkNo = 0\n",
    "        SigmaCtllhInv = 0\n",
    "        wt = 0\n",
    "\n",
    "    if ptNo > 0:\n",
    "        for xi in range(1, len(xAct) + 1):\n",
    "            row_indices = xAct[xi-1]-1\n",
    "            col_indices = ptAct-1\n",
    "            array = A[np.ix_([row_indices], col_indices)]\n",
    "            array_T = array.T\n",
    "            SigmaInv[:, :, xi-1] = (array * array_T) / sSq[xAct[xi-1]-1]\n",
    "    \n",
    "        SigmaCVInv = np.sum(SigmaInv, axis=2)\n",
    "        SigmaCInv = SigmaCVInv + 1 / (sigmaU**2) * np.eye(ptNo)\n",
    "        SigmaC = np.linalg.inv(SigmaCInv)\n",
    "\n",
    "        if SigmaC.size == 1:\n",
    "            ptAct = ptAct[0]\n",
    "            A_submatrix = A[xAct - 1, ptAct - 1]\n",
    "            A_submatrix = A_submatrix.reshape(-1, 1)\n",
    "            omega = omega - (1 / sigmaV**4) * (A_submatrix @ (SigmaC @ A_submatrix.T))\n",
    "        else:\n",
    "            A_submatrix = A[xAct - 1, :][:, ptAct - 1]\n",
    "            omega = omega - 1 / sigmaV**4 * (A_submatrix @ SigmaC @ A_submatrix.T)\n",
    "\n",
    "        omegaBU = np.zeros((N,N))\n",
    "        omegaBU[np.ix_(xAct-1, xAct-1)] = omega\n",
    "\n",
    "        for i in range(1, availLinkNo+1):\n",
    "            for j in range(1, availLinkNo+1):\n",
    "                if x[availLinks[i-1, 0]-1] == 1 and x[availLinks[j-1, 0]-1] == 1:\n",
    "                    SigmaCtllhInv[i-1, j-1] = (omegaBU[availLinks[i-1, 0]-1, availLinks[j-1, 0]-1] * \n",
    "                                               phi[availLinks[i-1, 0]-1, availLinks[i-1, 1]-1] * \n",
    "                                               phi[availLinks[j-1, 0]-1, availLinks[j-1, 1]-1])\n",
    "\n",
    "            vnan = np.nan_to_num(v)\n",
    "            #v array shape in the beginning is (12,144,2) due to matlab slicing, using python's (12,2)\n",
    "            first_term = phi[availLinks[i-1,0]-1, availLinks[i-1,1]-1]\n",
    "            second_term = omegaBU[availLinks[i-1,0]-1,:]\n",
    "            result1 = first_term * second_term\n",
    "            result1 = result1.reshape(1,-1)\n",
    "\n",
    "            third_term = np.sum(phi, axis=1) + 1\n",
    "            fourth_term_wt1 = vnan[:,0]\n",
    "            fourth_term_wt2 = vnan[:,1]\n",
    "\n",
    "            result2_wt1 = third_term * fourth_term_wt1\n",
    "            result2_wt2 = third_term * fourth_term_wt2\n",
    "            final_result_wt1 = np.dot(result1, result2_wt1)\n",
    "            final_result_wt2 = np.dot(result1, result2_wt2)\n",
    "\n",
    "            wt[i-1, 0] = final_result_wt1\n",
    "            wt[i-1, 1] = final_result_wt2\n",
    "\n",
    "    else:\n",
    "        SigmaC = 1\n",
    "\n",
    "    if type(SigmaC) == int:\n",
    "        det_SigmaC = 1\n",
    "    else:\n",
    "        det_SigmaC = np.linalg.det(SigmaC)\n",
    "\n",
    "    Psit = np.zeros((1, 1, 2))\n",
    "    vp = (1 + np.sum(phi, axis=1)) * v[:, 0]\n",
    "    vpnan = np.nan_to_num(vp)\n",
    "    Psit[:,:,0] = (2*np.pi)**(-xActNo/2) * sigmaU**(-ptNo) * 1/(np.sqrt(np.prod(sSq[xAct-1]))) * det_SigmaC**(0.5) * np.exp(-0.5 * np.dot(vpnan.T, np.dot(omegaBU, vpnan)))\n",
    "    \n",
    "    vp = (1 + np.sum(phi, axis=1)) * v[:, 1]\n",
    "    vpnan = np.nan_to_num(vp)\n",
    "    Psit[:,:,1] = (2*np.pi)**(-xActNo/2) * sigmaU**(-ptNo) * 1/(np.sqrt(np.prod(sSq[xAct-1]))) * det_SigmaC**(0.5) * np.exp(-0.5 * np.dot(vpnan.T, np.dot(omegaBU, vpnan)))\n",
    "    \n",
    "    return SigmaCtllhInv, wt, Psit, zc\n",
    "\n",
    "def calc_pv_training(x, v, y, Z, sigmaU, sigmaV, phi, sigmaC, *args):\n",
    "    nargs = len(args)\n",
    "    dims = args[0] if nargs > 0 else 0\n",
    "    logOutput = args[1] if nargs > 1 else 0\n",
    "\n",
    "    N, T = x.shape\n",
    "    K = Z.shape[1]\n",
    "    availLinkNo = int(np.sum(Z))\n",
    "    zc = np.zeros((N, K), dtype=bool)\n",
    "    zl = Z.astype(bool)\n",
    "    SigmaCtllhInv = np.zeros((availLinkNo, availLinkNo, T))\n",
    "    wt = np.zeros((availLinkNo, T, 2))\n",
    "    Psit = np.zeros((1, T, 2))\n",
    "\n",
    "    for t in range(1, T+1):\n",
    "\n",
    "        SigmaCtllhInv[:, :, t-1], wt[:, t-1, :], Psit[:, t-1, :], zct = calc_pv_trial(x[:, t-1:t], v[:, t-1, :] , y[:, t-1:t], Z, sigmaU, sigmaV, phi)\n",
    "        zc = np.bitwise_or(zc, zct)\n",
    "       \n",
    "    SigmaCTllhInv = np.sum(SigmaCtllhInv, axis=2)\n",
    "    SigmaCTpostInv = SigmaCTllhInv + np.diag(np.ones(availLinkNo)) / (sigmaC ** 2)\n",
    "    SigmaCTpost = np.linalg.inv(SigmaCTpostInv)\n",
    "    muCTpost = np.dot(SigmaCTpost, np.sum(wt[:, :, 0], axis=1))\n",
    "    muCTpost = muCTpost[:, np.newaxis]\n",
    "    muCTpost = np.concatenate((muCTpost, np.dot(SigmaCTpost, np.sum(wt[:,:,1], axis=1))[:, np.newaxis]), axis=1)\n",
    "   \n",
    "    muCTpostX = muCTpost[:, 0]\n",
    "    muCTpostY = muCTpost[:, 1]\n",
    "\n",
    "    #matches the result in matlab mvnormdfln\n",
    "    if np.sum(zc):\n",
    "        zc_zl = zc[zl]\n",
    "        nfx = multivariate_normal.logpdf(muCTpostX[zc_zl], mean=np.zeros(np.sum(zc)), cov=inv(SigmaCTpostInv[zc_zl, :][:, zc_zl]))\n",
    "        nfy = multivariate_normal.logpdf(muCTpostY[zc_zl], mean=np.zeros(np.sum(zc)), cov=inv(SigmaCTpostInv[zc_zl, :][:, zc_zl]))\n",
    "    else:\n",
    "        nfx = 0\n",
    "        nfy = 0\n",
    "\n",
    "    if logOutput == 0:\n",
    "        p1 = np.prod(Psit[:, :, 0]) * (2 * np.pi) ** (-np.sum(zc) / 2) * sigmaC ** (-np.sum(zc)) / np.exp(nfx)\n",
    "        p2 = np.prod(Psit[:, :, 1]) * (2 * np.pi) ** (-np.sum(zc) / 2) * sigmaC ** (-np.sum(zc)) / np.exp(nfy)\n",
    "\n",
    "        if dims == 0:\n",
    "            p = p1 * p2\n",
    "        elif dims == 1:\n",
    "            p = p1\n",
    "        elif dims == 2:\n",
    "            p = p2\n",
    "        else:\n",
    "            raise ValueError('calc_pv_training: wrong setting for optional argument dims')\n",
    "    else:\n",
    "        lp1 = np.sum(np.log(Psit[:, :, 0])) + np.log((2 * np.pi) ** (-np.sum(zc) / 2) * sigmaC ** (-np.sum(zc))) - nfx\n",
    "        lp2 = np.sum(np.log(Psit[:, :, 1])) + np.log((2 * np.pi) ** (-np.sum(zc) / 2) * sigmaC ** (-np.sum(zc))) - nfy\n",
    "\n",
    "        if dims == 0:\n",
    "            p = lp1 + lp2\n",
    "        elif dims == 1:\n",
    "            p = lp1\n",
    "        elif dims == 2:\n",
    "            p = lp2\n",
    "        else:\n",
    "            raise ValueError('calc_pv_training: wrong setting for optional argument dims')\n",
    "\n",
    "    return p, muCTpost, SigmaCTpostInv, SigmaCTpost\n",
    "\n",
    "def calc_px_training(X, Y, Z, lda, eps, *args):\n",
    "    nargs = len(args)\n",
    "    isLog = args[0] if nargs > 0 else 0\n",
    "\n",
    "    if Z.ndim == 1:  #cases (1,)  (2,)  (3,) (4,)\n",
    "        Z = Z.reshape(-1, 1) \n",
    "        pp = (1 - ((1 - lda) ** (Z.T @ Y)) * (1 - eps)) * X + (((1 - lda) ** (Z.T @ Y)) * (1 - eps)) * (1 - X)\n",
    "    else:  #cases (12,1) (12,3)\n",
    "        pp = (1 - ((1 - lda) ** (Z @ Y)) * (1 - eps)) * X + (((1 - lda) ** (Z @ Y)) * (1 - eps)) * (1 - X)\n",
    "\n",
    "    if isLog == 0:\n",
    "        p = np.prod(pp)\n",
    "    else:\n",
    "        pp = np.log(pp)\n",
    "        p = np.sum(pp)\n",
    "\n",
    "    return p\n",
    "\n",
    "def wood_make_gibbs_y_spatial(Y, X, V, Z, R, lda, eps, sigmaU, sigmaV, phi, sigmaC):\n",
    "\n",
    "    K, T = Y.shape\n",
    "    Ynew = Y.copy()\n",
    "\n",
    "    lpv_y = np.zeros((1, 2))\n",
    "    lpx_y = np.zeros((1, 2))\n",
    "    lpv_y_new, _, _, _ = calc_pv_training(X, V, Ynew, Z, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "    lpx_y_new = calc_px_training(X[:, 0:1], Ynew[:, 0:1], Z, lda, eps, 1)\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        for k in range(1, K + 1):\n",
    "            lpv_y[0, Ynew[k-1, t-1]] = lpv_y_new\n",
    "            lpx_y[0, Ynew[k-1, t-1]] = lpx_y_new\n",
    "\n",
    "            Ynew[k-1, t-1] = 1 - Ynew[k-1, t-1]\n",
    "\n",
    "            lpv_y[0, Ynew[k-1, t-1]], _, _, _ = calc_pv_training(X, V, Ynew, Z, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "            lpx_y[0, Ynew[k-1, t-1]] = calc_px_training(X[:, t-1:t], Ynew[:, t-1:t], Z, lda, eps, 1)\n",
    "\n",
    "            p = R[0, k-1]\n",
    "\n",
    "            lPYk1_ZXYmk = np.log(p) + lpx_y[0, 1] + lpv_y[0, 1]\n",
    "            lPYk0_ZXYmk = np.log(1 - p) + lpx_y[0, 0] + lpv_y[0, 0]\n",
    "\n",
    "            rt = np.exp(lPYk1_ZXYmk - lPYk0_ZXYmk)\n",
    "\n",
    "            if rt == np.inf:\n",
    "                PYk_ZXYmk = 1\n",
    "            else:\n",
    "                PYk_ZXYmk = rt / (rt + 1)\n",
    "\n",
    "            Ynew[k-1, t-1] = PYk_ZXYmk > np.random.rand(1,1)\n",
    "\n",
    "            lpv_y_new = lpv_y[0, Ynew[k-1, t-1]]\n",
    "            lpx_y_new = lpx_y[0, Ynew[k-1, t-1]]\n",
    "\n",
    "    return Ynew\n",
    "\n",
    "def wood_make_gibbs_z_spatial(Y, X, V, Z, R, lda, eps, sigmaU, sigmaV, phi, sigmaC, bAlpha, bBeta, alpha, Kmax, wburn, wsample):\n",
    "    \n",
    "    N, K = Z.shape\n",
    "    T = X.shape[1]\n",
    "\n",
    "    Znew = Z.copy()\n",
    "    lpv_y = np.zeros((1,2))\n",
    "    lpx_y = np.zeros((1,2))\n",
    "\n",
    "    wall = wburn + wsample\n",
    "\n",
    "    for n in range(1, N + 1):\n",
    "        Znew = Z.copy()\n",
    "        lpv_y_new, _, _, _ = calc_pv_training(X, V, Y, Znew, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "        lpx_y_new = calc_px_training(X[n-1, :], Y, Znew[n-1, :], lda, eps, 1)\n",
    "\n",
    "        for k in range(1, K + 1):\n",
    "            if n - 1 < N - 1:\n",
    "                m_mnk = np.sum(Znew[np.r_[0:n-1, n:N], k-1])\n",
    "            else:\n",
    "                m_mnk = np.sum(Znew[0:n-1, k-1])\n",
    "\n",
    "            th_k = m_mnk / N\n",
    "\n",
    "            if m_mnk > 0:\n",
    "                lpv_y[0, int(Znew[n-1, k-1])] = lpv_y_new\n",
    "                lpx_y[0, int(Znew[n-1, k-1])] = lpx_y_new\n",
    "\n",
    "                Znew[n-1, k-1] = 1 - Znew[n-1, k-1]\n",
    "\n",
    "                lpv_y[0, int(Znew[n-1, k-1])], _, _, _ = calc_pv_training(X, V, Y, Znew, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "                lpx_y[0, int(Znew[n-1, k-1])] = calc_px_training(X[n-1, :], Y, Znew[n-1, :], lda, eps, 1)\n",
    "\n",
    "                lPznk1_XZmnkY = np.log(th_k) + lpx_y[0, 1] + lpv_y[0, 1]\n",
    "                lPznk0_XZmnkY = np.log(1 - th_k) + lpx_y[0, 0] + lpv_y[0, 0]\n",
    "                \n",
    "                rt = np.exp(lPznk1_XZmnkY - lPznk0_XZmnkY)\n",
    "\n",
    "                if rt == np.inf:\n",
    "                    Pznk_XZmnkY = 1\n",
    "                else:\n",
    "                    Pznk_XZmnkY = rt / (rt + 1)\n",
    "            else:\n",
    "                Pznk_XZmnkY = 0\n",
    "\n",
    "            uni = np.random.rand()\n",
    "\n",
    "            Znew[n-1, k-1] = Pznk_XZmnkY > uni\n",
    "\n",
    "            lpv_y_new = lpv_y[0, int(Znew[n-1, k-1])]\n",
    "            lpx_y_new = lpx_y[0, int(Znew[n-1, k-1])]\n",
    "\n",
    "        Z = Znew.copy()\n",
    "        for k in range(1, K + 1):\n",
    "            R[0, k-1] = beta.rvs((bAlpha + np.sum(Y[k-1, :])), (bBeta + T - np.sum(Y[k-1, :])))\n",
    "\n",
    "        PKnew_XZY = np.zeros((1, Kmax + 1))\n",
    "        PKnew_XZY_an = np.zeros((1, Kmax + 1))\n",
    "        PKnew_XZY_5 = np.zeros((1, Kmax + 1))\n",
    "\n",
    "        Ysample = {}\n",
    "        Rsample = {}\n",
    "\n",
    "        for Knew in range(Kmax + 1):\n",
    "            lpy_xz = np.zeros((1, wsample))\n",
    "            ZAct = np.hstack((Z, np.zeros((N, Knew))))\n",
    "            if Knew > 0:\n",
    "                ZAct[n - 1, K:K + Knew] = 1\n",
    "            RAdd = beta.rvs(bAlpha, bBeta, size=(1,Knew))\n",
    "            RAct = np.hstack([R, RAdd])\n",
    "            if RAdd.shape == (1,0):\n",
    "                RAdd = 0\n",
    "\n",
    "            # rng result is different here, in matlab [1,0], in python [1,1]\n",
    "            YAct = np.vstack([Y, (np.random.rand(Knew, T) < np.tile(RAdd, (Knew, 1))).astype(int)])\n",
    "\n",
    "            lpv_y_act = np.zeros((1,2))\n",
    "            lpx_y_act = np.zeros((1,2))\n",
    "            \n",
    "            lpv_y_new, _, _, _ = calc_pv_training(X, V, YAct, ZAct, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "            lpx_y_new = calc_px_training(X[n-1, :], YAct, ZAct[n-1, :], lda, eps, 1)\n",
    "\n",
    "            if Knew > 0:\n",
    "                lpy_v = np.zeros(wsample)\n",
    "                lpy_x = np.zeros(wsample)\n",
    "                lpy_xv = np.zeros(wsample)\n",
    "                for wi in range(1, wall+1):\n",
    "                    for t in range(1, T + 1):\n",
    "                        for k in range(1, Knew + 1):\n",
    "                            lpv_y_act[0, int(YAct[K + k-1, t-1])] = lpv_y_new\n",
    "                            lpx_y_act[0, int(YAct[K + k-1, t-1])] = lpx_y_new\n",
    "\n",
    "                            YAct[K + k-1, t-1] = 1 - YAct[K + k-1, t-1]\n",
    "                            lpv_y_act[0, int(YAct[K + k-1, t-1])], _, _, _ = calc_pv_training(X, V, YAct, ZAct, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "                            lpx_y_act[0, int(YAct[K + k-1, t-1])] = calc_px_training(X[n-1, :], YAct, ZAct[n-1, :], lda, eps, 1)\n",
    "                            p = RAct[0, (K + k-1)]\n",
    "                            lPYk1_ZXYmk = np.log(p) + lpx_y_act[0,1] + lpv_y_act[0,1]\n",
    "                            lPYk0_ZXYmk = np.log(1 - p) + lpx_y_act[0,0] + lpv_y_act[0,0]\n",
    "\n",
    "                            rt = np.exp(lPYk1_ZXYmk - lPYk0_ZXYmk)\n",
    "\n",
    "                            if rt == np.inf:\n",
    "                                PYk1_ZXYmk = 1\n",
    "                            else:\n",
    "                                PYk1_ZXYmk = rt / (rt + 1)\n",
    "\n",
    "                            uni = np.random.uniform(0,1)\n",
    "\n",
    "                            YAct[K + k-1, t-1] = PYk1_ZXYmk > uni\n",
    "\n",
    "                            lpv_y_new = lpv_y_act[0, int(YAct[K + k-1, t-1])]\n",
    "                            lpx_y_new = lpx_y_act[0, int(YAct[K + k-1, t-1])]\n",
    "\n",
    "                    for k in range(1, Knew + 1):\n",
    "                        RAct[0, (K + k-1)] = beta.rvs(bAlpha + np.sum(YAct[K + k-1, :]), bBeta + T - np.sum(YAct[K + k-1, :]))\n",
    "\n",
    "                    if wi > wburn:\n",
    "                        lpy_v[wi - wburn - 1] = lpv_y_new\n",
    "                        lpy_x[wi - wburn - 1] = lpx_y_new\n",
    "                        lpy_xv[wi - wburn - 1] = lpx_y_new + lpv_y_new\n",
    "\n",
    "            else:\n",
    "                lpx_y_new = calc_px_training(X[n-1, :], YAct, ZAct[n-1, :], lda, eps, 1)\n",
    "                lpv_y_new, _, _, _ = calc_pv_training(X, V, YAct, ZAct, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "                lpy_xv = lpx_y_new + lpv_y_new\n",
    "\n",
    "            if Knew == 0:\n",
    "                py_xzKnew_5 = lpy_xv\n",
    "            else:\n",
    "                py_xzKnew_5 = np.log(wsample) - np.log(1) + np.max(lpy_xv) - np.log(np.sum(1.0 / np.exp(lpy_xv - np.max(lpy_xv))))\n",
    "\n",
    "            PKnew_XZY_5[0, Knew] = (py_xzKnew_5 + np.log(poisson.pmf(Knew, alpha / N)))\n",
    "\n",
    "            Ysample[Knew] = YAct\n",
    "            Rsample[Knew] = RAct\n",
    "\n",
    "        lpdf_5 = PKnew_XZY_5 - np.max(PKnew_XZY_5)\n",
    "        pdf_5 = np.exp(lpdf_5) / np.sum(np.exp(lpdf_5))\n",
    "\n",
    "        bar = np.random.rand()\n",
    "        #in MATLAB bar = 0.7792\n",
    "        j = 1\n",
    "        while np.sum(pdf_5.flatten()[:j]) < bar:\n",
    "            j += 1\n",
    "        Knew = j-1\n",
    "\n",
    "        Znew = np.hstack((Z, np.zeros((N, Knew))))\n",
    "        Znew[n-1, K:K + Knew] = 1\n",
    "\n",
    "        Z = Znew.copy()\n",
    "        Y = Ysample[Knew]\n",
    "        R = Rsample[Knew]\n",
    "\n",
    "        col_sums = np.sum(Z, axis=0)\n",
    "        nodes2keep = np.nonzero(col_sums)[0]\n",
    "        if nodes2keep.size > 0:\n",
    "            Z = Z[:, nodes2keep]\n",
    "            Y = Y[nodes2keep, :]\n",
    "            R = R[0, nodes2keep].reshape(1,-1)\n",
    "            K = Z.shape[1]\n",
    "        else:\n",
    "            Z = np.zeros((N, 1))\n",
    "            Y = np.zeros((1, T))\n",
    "            R = np.zeros((1, 1))\n",
    "            K = Z.shape[1]\n",
    "\n",
    "    Znew = Z\n",
    "    Ynew = Y\n",
    "    Rnew = R\n",
    "\n",
    "    return Znew, Ynew, Rnew\n",
    "\n",
    "def wood_ibp_learning_frontend(X, V, lda, eps, sigmaU, sigmaV, \n",
    "                               phi, sigmaC, alpha, bAlpha, bBeta, \n",
    "                               Kmax, wburn, wsample, stepNo, burnIn):\n",
    "    \n",
    "    initLatentNo = 1\n",
    "    \n",
    "    # 12 x 144\n",
    "    N, T = X.shape\n",
    "\n",
    "    # 12 x 1\n",
    "    Znew = np.zeros((N, initLatentNo))\n",
    "\n",
    "    # 1 x 1\n",
    "    Rnew = beta.rvs(bAlpha, bBeta, size=(1, initLatentNo))\n",
    "\n",
    "    # 144 x 12\n",
    "    Ynew = np.array((np.random.rand(initLatentNo, T) < np.tile(Rnew.T, (1, T))), dtype=int)\n",
    "\n",
    "    Zpost = np.empty((1, stepNo - burnIn), dtype=object)\n",
    "    Ypost = np.empty((1, stepNo - burnIn), dtype=object)\n",
    "    Rpost = np.empty((1, stepNo - burnIn), dtype=object)\n",
    "    muCTpost = np.empty((1, stepNo - burnIn), dtype=object)\n",
    "    sigmaCTpost = np.empty((1, stepNo - burnIn), dtype=object)\n",
    "\n",
    "    for i in range(1, stepNo+1):\n",
    "        print(\"#\" * 50)\n",
    "        print(f\"iteration: {i-1}\")\n",
    "        print(f\"Znew = \\n{Znew}\\n\")\n",
    "        print(f\"Rnew = \\n{Rnew}\\n\")\n",
    "\n",
    "        Ynew = wood_make_gibbs_y_spatial(Ynew, X, V, Znew, Rnew, lda, eps, sigmaU, sigmaV, phi, sigmaC)\n",
    "        \n",
    "        Znew, Ynew, Rnew = wood_make_gibbs_z_spatial(Ynew, X, V, Znew, Rnew, lda, eps, sigmaU, sigmaV, phi, sigmaC, bAlpha, bBeta, alpha, \n",
    "                                                     Kmax, wburn, wsample)\n",
    "\n",
    "        pi, muCTposti, SigmaCTpostInvi, sigmaCTposti = calc_pv_training(X, V, Ynew, Znew, sigmaU, sigmaV, phi, sigmaC, 0, 1)\n",
    "\n",
    "        if i > burnIn:\n",
    "            Zpost[0, i - burnIn - 1] = Znew\n",
    "            Ypost[0, i - burnIn - 1] = Ynew\n",
    "            Rpost[0, i - burnIn - 1] = Rnew\n",
    "            muCTpost[0, i - burnIn - 1] = muCTposti\n",
    "            sigmaCTpost[0, i - burnIn - 1] = sigmaCTposti\n",
    "\n",
    "    return Zpost, Ypost, Rpost, muCTpost, sigmaCTpost, Kmax, wburn, wsample\n",
    "\n",
    "Zpost, Ypost, Rpost, muCTpost, sigmaCTpost, Kmax, wburn, wsample = wood_ibp_learning_frontend(X[:, :trainingLength], V[:, :trainingLength, :], \n",
    "                                                                                                lda, eps, sigmaU, sigmaV, phi, sigmaC,alpha, \n",
    "                                                                                                bAlpha, bBeta, Kmax, wburn, wsample, stepNo, burnIn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bap3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
